# -*- coding: utf-8 -*-
"""Garbage-Classification-Using-CNN-And-AlexNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bdEyt4UMfyukhkiTk8dG58Sq7jApl9Em

# **üîó 1. Import & Setup Kaggle Dataset**
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
import kagglehub
asdasdasasdas_garbage_classification_path = kagglehub.dataset_download('asdasdasasdas/garbage-classification')
print('Data source import complete.')

"""# **üß∞ 2. Import Libraries**"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

"""# **‚öôÔ∏è 3. Configuration & Hyperparameters**"""

train_dir = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'
labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']

IMAGE_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001
DROPOUT = 0.4
OPTIMIZER = keras.optimizers.Adam(learning_rate=LEARNING_RATE)

"""# **üñºÔ∏è 4. Display Sample Images per Class**"""

plt.figure(figsize=(30, 14))
for i in range(6):
    directory = os.path.join(train_dir, labels[i])
    for j in range(10):
        path = os.path.join(directory, os.listdir(directory)[j])
        img = mpimg.imread(path)
        plt.subplot(6, 10, i*10 + j + 1)
        plt.imshow(img)
        if j == 0:
            plt.ylabel(labels[i], fontsize=20)
plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])
plt.tight_layout()
plt.show()

"""# **üß™ 5. Image Data Generators**"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    zoom_range=0.1,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode="nearest",
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
    class_mode='sparse', subset='training', shuffle=True
)

validation_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
    class_mode='sparse', subset='validation', shuffle=False
)

"""# **üß† 6. CNN Model Definition**"""

def create_cnn():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(*IMAGE_SIZE, 3)),
        BatchNormalization(),
        Conv2D(32, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.2),

        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.2),

        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.2),

        Conv2D(256, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(256, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.2),

        Flatten(),
        Dense(512, activation='relu'),
        BatchNormalization(),
        Dropout(DROPOUT),
        Dense(6, activation='softmax')
    ])
    return model

"""# **üéØ 7. Load or Train the Model**"""

model_path = 'garbage_classifier_model.h5'

if os.path.exists(model_path):
    print("Loading saved model...")
    model = load_model(model_path)
else:
    print("Training new model...")
    model = create_cnn()
    model.compile(loss='sparse_categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])

    class myCallback(tf.keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs={}):
            if logs.get('accuracy') > 0.90:
                print("\nReached 90% accuracy, stopping training.")
                self.model.stop_training = True

    callbacks = myCallback()
    history = model.fit(
        train_generator, epochs=EPOCHS, validation_data=validation_generator,
        callbacks=[callbacks], verbose=1
    )
    model.save(model_path)

"""# **üìä 8. Model Evaluation**"""

print("Evaluating model...")
val_preds = model.predict(validation_generator)
y_pred = np.argmax(val_preds, axis=1)
y_true = validation_generator.classes

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='BuPu', fmt='g',
            xticklabels=labels, yticklabels=labels,
            linewidths=0.5, linecolor='white')




plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=labels))

# Class-wise Accuracy
print("\nClass-wise Accuracy:")
for i, label in enumerate(labels):
    correct = np.sum((y_pred == y_true) & (y_true == i))
    total = np.sum(y_true == i)
    print(f"{label}: {correct/total:.2%}")

"""# **üß™ 9. Interactive Image Prediction (Category + Index Picker)**

"""

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import tensorflow as tf
from PIL import Image

# ---- Setup ----
train_dir = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'
labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
IMAGE_SIZE = (224, 224)  # Update to match model input

# Load the pre-trained model
model = tf.keras.models.load_model('/content/garbage_classifier_model.h5')

# ---- Function to Load and Predict ----
def predict_from_folder(category_idx, image_idx):
    try:
        folder = os.path.join(train_dir, labels[category_idx])
        file_list = sorted(os.listdir(folder))
        img_path = os.path.join(folder, file_list[image_idx])
        img = mpimg.imread(img_path)

        # Show Image
        plt.imshow(img)
        plt.title(f"Selected Image from '{labels[category_idx]}'")
        plt.axis('off')
        plt.show()

        # Preprocess
        test_img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        test_array = tf.keras.preprocessing.image.img_to_array(test_img)
        test_array = np.expand_dims(test_array, axis=0) / 255.0  # Normalize to [0,1]

        # Predict
        pred = model.predict(test_array)
        pred_label = labels[np.argmax(pred)]
        print(f"\nüîç Predicted Class: {pred_label}")

    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")

# ---- Loop Interface ----
while True:
    print("\nSelect a category:")
    for i, label in enumerate(labels):
        print(f"{i}: {label}")
    try:
        cat_idx = int(input("Enter category index (0-5): "))
        folder_path = os.path.join(train_dir, labels[cat_idx])
        files = os.listdir(folder_path)
        print(f"Available images: 0 to {len(files)-1}")
        img_idx = int(input("Enter image index: "))
        predict_from_folder(cat_idx, img_idx)
    except Exception as e:
        print(f"Invalid input: {e}")

    again = input("\nDo you want to predict another? (y/n): ")
    if again.lower() != 'y':
        break